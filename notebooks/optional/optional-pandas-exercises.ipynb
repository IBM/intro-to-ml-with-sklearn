{"cells":[{"metadata":{},"cell_type":"markdown","source":["# Working with structured data in Python using Pandas\n","\n","### What is data preprocessing? \n","\n","Process of converting raw data into useful format.In order to better understand the data, we need to gather some statistical insights into our data. In this module of the course, we will use some of the libraries available with Python and Jupyter to examine our data set. \n","\n","### What is pandas? \n","\n","[pandas](https://pandas.pydata.org/) is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,\n","built on top of the Python programming language.\n","\n","### Data\n","\n","We'll use a data set from [Kaggle](https://www.kaggle.com/) for this workshop. You'll need to download it to your local machine, then upload to your project running in Cloud Pak for Data as a Service.\n","\n","The *insurance.csv* dataset acquired from *Kaggle*  contains 1338 observations (rows) and 7 features (columns). The dataset contains 4 numerical features (age, bmi, children and expenses) and 3 nominal features (sex, smoker and region) that were converted into factors with numerical value designated for each level.\n","\n","We'll continue to use the [`insurance.csv`](https://www.kaggle.com/noordeen/insurance-premium-prediction/download) file from you project assets, so if you have not already [`downloaded this file`](https://www.kaggle.com/noordeen/insurance-premium-prediction/download) to your local machine, and uploaded it to your project, do that now.\n","\n","## Table of Contents\n","\n","1. [Using the Jupyter notebook](#jupyter)<br>\n","1. [Series and DataFrames](#series)<br>\n","1. [Loading Data](#loading)<br>\n","1. [Exploring Data](#exploring)<br>\n","1. [Cleaning Data](#cleaning)<br>\n","1. [Analyzing Data](#selection)<br>"]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"jupyter\"></a>\n","## 1. Using the Jupyter notebook"]},{"metadata":{},"cell_type":"markdown","source":["### Jupyter cells\n","\n","When you are editing a cell in Jupyter notebook, you need to re-run the cell by pressing **`<Shift> + <Enter>`**. This will allow changes you made to be available to other cells.\n","\n","Use **`<Enter>`** to make new lines inside a cell you are editing.\n","\n","#### Code cells\n","\n","Re-running will execute any statements you have written. To edit an existing code cell, click on it.\n","\n","#### Markdown cells\n","\n","Re-running will render the markdown text. To edit an existing markdown cell, double-click on it.\n","\n","<hr>\n","\n","### Common Jupyter operations\n","\n","Near the top of the Jupyter notebook page, Jupyter provides a row of menu options (`File`, `Edit`, `View`, `Insert`, ...) and a row of tool bar icons (disk, plus sign, scissors, 2 files, clipboard and file, up arrow, ...).\n","\n","#### Inserting and removing cells\n","\n","- Use the \"plus sign\" icon to insert a cell below the currently selected cell\n","- Use \"Insert\" -> \"Insert Cell Above\" from the menu to insert above\n","\n","#### Clear the output of all cells\n","\n","- Use \"Kernel\" -> \"Restart\" from the menu to restart the kernel\n","    - click on \"clear all outputs & restart\" to have all the output cleared\n","\n","#### Save your notebook file locally\n","\n","- Clear the output of all cells\n","- Use \"File\" -> \"Download as\" -> \"IPython Notebook (.ipynb)\" to download a notebook file representing your session\n","\n","<hr>"]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"series\"></a>\n","## 2. Series and DataFrames \n","\n","Before we dive into our dataset we will first look at examples to understand the difference between two key data structures that pandas offers us - *Series* and *DataFrames*\n","\n","A `Series` is a one-dimensional labelled array that can contain of any type (integer, string, float, python objects, etc.)."]},{"metadata":{},"cell_type":"code","source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["s = pd.Series\n","([1, 3, 5, np.nan, 6, 8])\n","ss = pd.Series\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["A `DataFrame` is a two-dimensional data structure, the data consists of rows and columns that you can create a in many ways, by loading a file or using a NumPy array and a date for the index.\n","\n","<div class=\"alert alert-info\" style=\"font-size:100%\">\n","<a href=\"https://numpy.org\"> NumPy</a> is a Python library for working with multi-dimensional arrays and matrices with a large collection of mathematical functions to operate on these arrays.\n","Have a look at this <a href=\"https://docs.scipy.org/doc/numpy-1.15.0/user/quickstart.html\"> NumPy tutorial</a> for an overview.\n","</div>\n","\n"]},{"metadata":{},"cell_type":"markdown","source":["Create DataFrame `df1` with `dates` as the index, a 6 by 4 array of random `numbers` as values, and column names A, B, C and D (the index will be explained in the next section):  "]},{"metadata":{},"cell_type":"code","source":["dates = pd.date_range('20200101', periods=6)\n","dates"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["numbers = np.random.randn(6, 4)\n","numbers"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df1 = pd.DataFrame(numbers, index=dates, columns=['A', 'B', 'C', 'D'])\n","df1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Or create a DataFrame by combining the above in one command:"]},{"metadata":{},"cell_type":"code","source":["df2 = pd.DataFrame({'A': 1.,\n","                     'B': pd.Timestamp('20130102'),\n","                     'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n","                     'D': np.array([3] * 4, dtype='int32'),\n","                     'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n","                     'F': 'foo'})"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df2.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Use `type()` to check the data type of each variable. Below `print` is used to display the data type of all of them used so far:"]},{"metadata":{},"cell_type":"code","source":["print('Data type of s is '+str(type(s)))\n","print('Data type of s is '+str(type(dates)))\n","print('Data type of s is '+str(type(numbers)))\n","print('Data type of df is '+str(type(df1)))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"data\"></a>\n","## 3 Loading data \n","\n","A lot of data is **structured data**, which is data that is organized and formatted so it is easily readable, for example a table with variables as columns and records as rows, or key-value pairs in a noSQL database. As long as the data is formatted consistently and has multiple records with numbers, text and dates, you can probably read the data with [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html), an open-source Python package providing high-performance data manipulation and analysis.\n","\n","### 3.1 Load our data as a pandas data frame\n","\n","**<font color='red'><< FOLLOW THE INSTRUCTIONS BELOW TO LOAD THE DATASET >></font>**\n","\n","* Highlight the cell below by clicking it.\n","* Click the `10/01` \"Find data\" icon in the upper right of the notebook.\n","* Add the locally uploaded file `insurance.csv` by choosing the `Files` tab. Then choose the `insurance.csv`. Click `Insert to code` and choose `Insert Pandas DataFrame`.\n","* The code to bring the data into the notebook environment and create a Pandas DataFrame will be added to the cell below.\n","* Run the cell"]},{"metadata":{},"cell_type":"code","source":["# Place cursor below and insert the Pandas DataFrame for the Insurance Expense data\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 3.2 Update the variable for our Pandas dataframe\n","\n","We'll use the Pandas naming convention df for our DataFrame. Make sure that the cell below uses the name for the dataframe used above. For the locally uploaded file it should look like df_data_1 or df_data_2 or df_data_x. \n","\n","**<font color='red'><< UPDATE THE VARIABLE ASSIGNMENT TO THE VARIABLE GENERATED ABOVE. >></font>**"]},{"metadata":{},"cell_type":"code","source":["# Replace data_df_1 with the variable name generated above.\n","df = df_data_1"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["**OPTIONAL : Read data from a CSV file using the `read_csv` function. Load a file by running the next cell:**\n","\n","The file can also be read directly from a URL, but you can replace this with a local path when running this notebook on a local system."]},{"metadata":{},"cell_type":"raw","source":["df = pd.read_csv('URL',encoding = 'unicode_escape', sep=',', thousands=',')"]},{"metadata":{},"cell_type":"markdown","source":["## 4. Exploring Data"]},{"metadata":{},"cell_type":"markdown","source":["Now let's have a look at the data that was loaded into the notebook. What are we actually looking at?"]},{"metadata":{},"cell_type":"markdown","source":["####   `df.shape` gives the number of rows and columns"]},{"metadata":{},"cell_type":"code","source":["df.shape"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df.info()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  `len(df)` gives the number of rows"]},{"metadata":{},"cell_type":"code","source":["len(df)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  Use `df.dtypes` to check the different variables and their datatype"]},{"metadata":{},"cell_type":"code","source":["df.dtypes"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  `df.columns` gives a list of all column names"]},{"metadata":{},"cell_type":"code","source":["df.columns"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["list(df)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["all_columns         = list(df)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  *select_dtypes* can be used to list columns of a particular datatype. In the cell below, we list numerical columns. "]},{"metadata":{},"cell_type":"code","source":["numerical_columns     = list(df.select_dtypes(include=['float64','int64']).columns)\n","\n","print('Numerical columns : ')\n","print(numerical_columns)\n"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["and in the cell below, we identify categorical columns from the dataset. "]},{"metadata":{},"cell_type":"code","source":["categorical_columns = [x for x in all_columns if x not in numerical_columns ]\n","\n","print('Categorical columns : ')\n","print(categorical_columns)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  *nunique()* is used to identify number of unique values within each column in the dataset"]},{"metadata":{},"cell_type":"code","source":["df.nunique()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df.values"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":[" ####  With `df.head()` or `df.tail()` you can view the first five or last five lines from the data. Add a number between the brackets `()` to specify the number of lines you want to display., e.g. `df.head(2)`"]},{"metadata":{},"cell_type":"code","source":["df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df.head(2)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["df.tail()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"cleaning\"></a>\n","## 5. Cleaning Data\n","\n","When exploring data there are always transformations needed to get it in the format you need for your analysis, visualisations or models. Below are only a few examples of the endless possibilities. "]},{"metadata":{},"cell_type":"markdown","source":["First, let's make a copy of the Dataframe :"]},{"metadata":{},"cell_type":"code","source":["premium_df = df.copy()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["premium_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.1 Adding and deleting columns\n","\n","Adding a column can be done by creating a new column `new`, which can be dropped using the `drop` function."]},{"metadata":{},"cell_type":"code","source":["premium_df['new'] = 1\n","premium_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["premium_df = premium_df.drop(columns='new')\n","premium_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.2 Rename columns"]},{"metadata":{},"cell_type":"code","source":["print(\"Column names before rename : \", premium_df.columns)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"Renaming\"></a>\n","\n","You can change names of columns using `rename`:"]},{"metadata":{},"cell_type":"code","source":["premium_df.rename(columns={'sex':'gender'},\n","                 inplace=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["print(\"Column names after rename : \", premium_df.columns)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["premium_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 5.3 Further Data Cleaning\n","\n","**Things to check:**\n","\n","* Is the data tidy: each variable forms a column, each observation forms a row and  each type of observational unit forms a table.\n","* Are all columns in the right data format?\n","* Are there missing values?\n","* Are there unrealistic outliers?"]},{"metadata":{},"cell_type":"markdown","source":["####  Check if all datatypes are as you expect with `dtypes`:"]},{"metadata":{},"cell_type":"code","source":["premium_df.dtypes"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  Check if there are missing values with `isna`:"]},{"metadata":{},"cell_type":"code","source":["premium_df.isna().any()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  Get a quick overview of the numeric data using the `.describe()` function. If any of the numeric columns are missing from this list this is a probably because of a wrong data type. This will include numeric data, but exclude the categorical fields."]},{"metadata":{},"cell_type":"code","source":["premium_df_describe = premium_df.describe()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"code","source":["premium_df_describe"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["####  Get the list of unique values within each column using `unique()`"]},{"metadata":{},"cell_type":"code","source":["print(premium_df['region'].unique())"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["\n","## 6. Analyzing data \n","\n","We will analyze the data by asking one or more hypothetical questions. \n","\n","### Question : Is there a relationship between smoking and claim amount? \n","\n","Let us learn few other functionalities of pandas in trying to answer the above question.  "]},{"metadata":{},"cell_type":"markdown","source":["From the original dataframe, let us now create a new DataFrame with just these 2 columns:"]},{"metadata":{},"cell_type":"code","source":["premium_smoker_df = premium_df[['smoker', 'expenses']]\n","premium_smoker_df.head()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.1 Get smoker counts"]},{"metadata":{},"cell_type":"markdown","source":["#### Let us now apply some filtering to analyze information about smokers from the dataset.  \n","\n","Filtering - selecting rows based on a certain condition can be done with Boolean indexing. This uses the actual values of the data in the DataFrame as opposed to the row/column labels or index positions."]},{"metadata":{},"cell_type":"code","source":["premium_smoker_df['smoker'] == 'yes'"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["First we will print number of entries with value for smoker marked as 'yes'. When you want to select the rows and see all the data add `premium_smoker_df[]` around your function:"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["print(len(premium_smoker_df[premium_smoker_df['smoker'] == 'yes']))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Next we will print number of entries with value for smoker marked as 'no'."]},{"metadata":{},"cell_type":"code","source":["print(len(premium_smoker_df[premium_smoker_df['smoker'] == 'no']))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["Alternatively, we can use the `value_counts()` method to get the counts with each value."]},{"metadata":{},"cell_type":"code","source":["df.smoker.value_counts()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.2  Visualize smoker data\n","\n","We use pandas' in-built plotting method to visualize a pie chart. This internally uses *matplotlib*"]},{"metadata":{},"cell_type":"code","source":["df.smoker.value_counts().plot(kind=\"pie\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id=\"grouping\"></a>\n","### 6.3  *smoker* vs *expenses* statistics \n","\n","We use the `decribe()` method to analyze relation between the *smoker* and the *expenses* feature"]},{"metadata":{"scrolled":true},"cell_type":"code","source":["df.groupby(['smoker']).expenses.describe()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.4 *smoker* vs *age* statistics\n","\n","We use the `mean()` method to analyze relation between the *smoker* and the *age* column"]},{"metadata":{},"cell_type":"code","source":["df.groupby(\"smoker\").age.mean()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["### 6.5 Correlation between features\n","\n","Pandas also offers a `corr()` method to define a correlation table between all features. A score of 1.0 means highest correlation and 0.0 means no correlation. "]},{"metadata":{},"cell_type":"code","source":["df[['age', 'sex','bmi', 'children', 'smoker', 'region', 'expenses']].corr(method='pearson')"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}