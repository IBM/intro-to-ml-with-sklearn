{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction to Machine Learning with sklearn \u00b6 Welcome to the workshop! In this workshop we'll be using Jupyter notebooks to learn about and practice machine learning with scikit learn framework ( sklearn ). We use IBM Cloud Pak for Data as a Service (CP4DaaS) to run the notebooks and build a Machine Learning model with the scikit , and we'll demonstrate AutoAI which automated the process of building machine learning models. Agenda \u00b6 Topic Description Length Welcome Introduction to workshop 0:10 Machine Learning Overview What is Machine Learning and How it works 0:15 Notebook: Python for ML Refresher Refresher for primary tools used in ML 0:20 Notebook: Regression Training your first Regression Model 0:30 BREAK 0:15 AutoAI - Intro and Setup Setting up your AutoAI experiment 0:10 Notebook: Classification Training your first classification model 0:30 AutoAI - Review Results Understanding the results of your AutoAI experiment 0:05 Summary + Survey Review of workshop and next steps 0:05 Compatability \u00b6 This workshop has been tested on IBM Watson Studio and Cloud Pak for Data as a Service . The notebooks use Python 3.8 .","title":"About this workshop"},{"location":"#introduction-to-machine-learning-with-sklearn","text":"Welcome to the workshop! In this workshop we'll be using Jupyter notebooks to learn about and practice machine learning with scikit learn framework ( sklearn ). We use IBM Cloud Pak for Data as a Service (CP4DaaS) to run the notebooks and build a Machine Learning model with the scikit , and we'll demonstrate AutoAI which automated the process of building machine learning models.","title":"Introduction to Machine Learning with sklearn"},{"location":"#agenda","text":"Topic Description Length Welcome Introduction to workshop 0:10 Machine Learning Overview What is Machine Learning and How it works 0:15 Notebook: Python for ML Refresher Refresher for primary tools used in ML 0:20 Notebook: Regression Training your first Regression Model 0:30 BREAK 0:15 AutoAI - Intro and Setup Setting up your AutoAI experiment 0:10 Notebook: Classification Training your first classification model 0:30 AutoAI - Review Results Understanding the results of your AutoAI experiment 0:05 Summary + Survey Review of workshop and next steps 0:05","title":"Agenda"},{"location":"#compatability","text":"This workshop has been tested on IBM Watson Studio and Cloud Pak for Data as a Service . The notebooks use Python 3.8 .","title":"Compatability"},{"location":"00-project-setup/","text":"Workshop Setup \u00b6 Before we get started with the workshop, you will need to download some assets and setup your environment. This section is broken up into the following steps: Download Assets Create IBM Cloud account and service Create a project Info You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page. 1. Download Assets \u00b6 Throughout this workshop, you'll be asked to run different notebooks. These artifacts have been collected in the following zip file which you can download using the links below. For each line below, click on the [Download] link to get the file. If the link isn't working for you, try clicking the [Mirror] to get it from a backup server. You'll need these files in the next sections. Download the project Attention DO NOT unzip the downloaded file. Specifically, MacOS unzips and removes the zipped file that you just downloaded if you double click on it. Cloud Pak for Data needs the zipped file so make sure you do not accidentally unzip it. 2. Create IBM Cloud account and service \u00b6 We need to provision our Cloud Pak for Data as a Service instance. Cloud Pak for Data provides you with an integrated set of capabilities for collecting and organizing your data into a trusted, unified view, and then creating and scaling AI models across your business. Launch a web browser and navigate to IBM Cloud Pak for Data using the region US, Dallas. You can then log in using your IBMid if you have one or create a new IBMid. If you do not have an IBMid, enter your email address and accept the terms checkbox in the Create a new IBM Cloud Account section. Then click the Next button to complete the process of creating a new account. See the FAQ section for help. If you are a returning user, click on the Log in with your IBMid link. Info If you are a returning user and you have watson services in a different region than the pre-selected one, you will see an error message telling you to select that region instead. See the FAQ section for help. The services required for IBM Cloud Pak for Data will be automatically provisioned for you. Once you see a message that says that the apps are ready to use, click on Go to IBM Cloud Pak for Data . 3. Create a project \u00b6 Import the Project \u00b6 In Cloud Pak for Data, we use the concept of a project to collect / organize the resources used to achieve a particular goal (resources to build a solution to a problem). Your project resources can include data, collaborators, and analytic assets like notebooks and models, etc. Once you are on Cloud Pak for Data as a Service . Click on the (\u2630) navigation menu on the top left, expand Projects and click on the View all projects link. Click on the New project button on the top. Info If you already have existing projects, your screen will look different from the screenshot below. In that case, click on the New project + button on the top right. Click on Create a project from a sample or file . Click on the browse link and in the file browser popup, navigate to where you downloaded the files for this lab. Then select the intro-to-ml-cp4daas.zip . Click Create . Attention Remember that you need the zipped file. If you have accidentally unzipped it, download the file again from the Download Assets section. Give the project a name and optional description. You also need to provide an object storage instance for this project. If you have not previously created a Cloud Object Storage instance in your IBM Cloud account, you can create one now by clicking Add . Note: If you do have an existing storage service, select it from the drop down list and click the Create button. A new tab opens up, where you can create the Cloud Object Service. By default, a Lite (Free) plan will be selected. Scroll down and update the name of your Cloud Object Storage service if you wish, and click Create . The browser tab will automatically close when the Cloud Object Storage instance has been created. Back on IBM Cloud Pak for Data as a Service, click Refresh . The newly created Cloud Object Storage instance will now be displayed under \"Storage\". Click Create to finish creating the project. Once the project is successfully created you will be brought to the project overview page ( Note:You may be presented with a project tour pop up window, go ahead and close it ) 4. Create a Space for Machine Learning Deployments \u00b6 Cloud Pak for Data uses the concept of Deployment Spaces to configure and manage the deployment of a set of related deployable assets. These assets can be data files, machine learning models, etc. Go the (\u2630) navigation menu, expand Deployments and click View all spaces . Click on the New deployment space + button. Give your deployment space a unique name, optional description, then click the Create button. From the deployment space creation pop up window, click on the View new space button to view your space. FAQ \u00b6 Q1: I get the That email address is already registered to an IBM Cloud account. messsage. A: You must already have an IBMid account. Follow the login link provided in the error message to login to your existing account. Q2: The Sign Up process was unsuccessful. A: Try creating a IBM Cloud account directly using IBM Cloud Registration in a different browser first. Once you have your IBM Cloud account set up, you can use the link in Section 2 . 6. Conclusion \u00b6 At this point we are done with this section. We have completed creating an IBM Cloud account, a Cloud Pak for Data as a Service instance, the project that we will use in the rest of this workshop and the deployment space where we will deploy our ML models.","title":"Workshop Set Up"},{"location":"00-project-setup/#workshop-setup","text":"Before we get started with the workshop, you will need to download some assets and setup your environment. This section is broken up into the following steps: Download Assets Create IBM Cloud account and service Create a project Info You can click on any image in the instructions below to zoom in and see more details. When you do that just click on your browser's back button to return to the previous page.","title":"Workshop Setup"},{"location":"00-project-setup/#1-download-assets","text":"Throughout this workshop, you'll be asked to run different notebooks. These artifacts have been collected in the following zip file which you can download using the links below. For each line below, click on the [Download] link to get the file. If the link isn't working for you, try clicking the [Mirror] to get it from a backup server. You'll need these files in the next sections. Download the project Attention DO NOT unzip the downloaded file. Specifically, MacOS unzips and removes the zipped file that you just downloaded if you double click on it. Cloud Pak for Data needs the zipped file so make sure you do not accidentally unzip it.","title":"1. Download Assets"},{"location":"00-project-setup/#2-create-ibm-cloud-account-and-service","text":"We need to provision our Cloud Pak for Data as a Service instance. Cloud Pak for Data provides you with an integrated set of capabilities for collecting and organizing your data into a trusted, unified view, and then creating and scaling AI models across your business. Launch a web browser and navigate to IBM Cloud Pak for Data using the region US, Dallas. You can then log in using your IBMid if you have one or create a new IBMid. If you do not have an IBMid, enter your email address and accept the terms checkbox in the Create a new IBM Cloud Account section. Then click the Next button to complete the process of creating a new account. See the FAQ section for help. If you are a returning user, click on the Log in with your IBMid link. Info If you are a returning user and you have watson services in a different region than the pre-selected one, you will see an error message telling you to select that region instead. See the FAQ section for help. The services required for IBM Cloud Pak for Data will be automatically provisioned for you. Once you see a message that says that the apps are ready to use, click on Go to IBM Cloud Pak for Data .","title":"2. Create IBM Cloud account and service"},{"location":"00-project-setup/#3-create-a-project","text":"","title":"3. Create a project"},{"location":"00-project-setup/#import-the-project","text":"In Cloud Pak for Data, we use the concept of a project to collect / organize the resources used to achieve a particular goal (resources to build a solution to a problem). Your project resources can include data, collaborators, and analytic assets like notebooks and models, etc. Once you are on Cloud Pak for Data as a Service . Click on the (\u2630) navigation menu on the top left, expand Projects and click on the View all projects link. Click on the New project button on the top. Info If you already have existing projects, your screen will look different from the screenshot below. In that case, click on the New project + button on the top right. Click on Create a project from a sample or file . Click on the browse link and in the file browser popup, navigate to where you downloaded the files for this lab. Then select the intro-to-ml-cp4daas.zip . Click Create . Attention Remember that you need the zipped file. If you have accidentally unzipped it, download the file again from the Download Assets section. Give the project a name and optional description. You also need to provide an object storage instance for this project. If you have not previously created a Cloud Object Storage instance in your IBM Cloud account, you can create one now by clicking Add . Note: If you do have an existing storage service, select it from the drop down list and click the Create button. A new tab opens up, where you can create the Cloud Object Service. By default, a Lite (Free) plan will be selected. Scroll down and update the name of your Cloud Object Storage service if you wish, and click Create . The browser tab will automatically close when the Cloud Object Storage instance has been created. Back on IBM Cloud Pak for Data as a Service, click Refresh . The newly created Cloud Object Storage instance will now be displayed under \"Storage\". Click Create to finish creating the project. Once the project is successfully created you will be brought to the project overview page ( Note:You may be presented with a project tour pop up window, go ahead and close it )","title":"Import the Project"},{"location":"00-project-setup/#4-create-a-space-for-machine-learning-deployments","text":"Cloud Pak for Data uses the concept of Deployment Spaces to configure and manage the deployment of a set of related deployable assets. These assets can be data files, machine learning models, etc. Go the (\u2630) navigation menu, expand Deployments and click View all spaces . Click on the New deployment space + button. Give your deployment space a unique name, optional description, then click the Create button. From the deployment space creation pop up window, click on the View new space button to view your space.","title":"4. Create a Space for Machine Learning Deployments"},{"location":"00-project-setup/#faq","text":"Q1: I get the That email address is already registered to an IBM Cloud account. messsage. A: You must already have an IBMid account. Follow the login link provided in the error message to login to your existing account. Q2: The Sign Up process was unsuccessful. A: Try creating a IBM Cloud account directly using IBM Cloud Registration in a different browser first. Once you have your IBM Cloud account set up, you can use the link in Section 2 .","title":"FAQ"},{"location":"00-project-setup/#6-conclusion","text":"At this point we are done with this section. We have completed creating an IBM Cloud account, a Cloud Pak for Data as a Service instance, the project that we will use in the rest of this workshop and the deployment space where we will deploy our ML models.","title":"6. Conclusion"},{"location":"01-python-and-pandas-refresher/","text":"Python for ML Refresher \u00b6 In this section we will do a quick review of the following topics which will help you refresh your python skills so you can follow the rest of this workshop. Note that while you could greatly benefit from the optional sections, you don't have to follow them for this workshop. Definitions What is Python What is a Jupyter Notebook What is Pandas What is Seaborn Exercises Refresher Open the Jupyter notebook Run the Jupyter notebook Optional Introductory Exercises 1. Definitions \u00b6 1.1 What is Python \u00b6 You might think that Python is only for developers and people with computer science degrees. However, Python is great for beginners, even those with little coding experience because it\u2019s free, open source, and runs on any platform. The Python packages documentation is great, and after an introductory course , you have a good foundation to build on. For Data Scientists, Python has become an invaluable tool. This notebook will help you get started or review the basics of Python. 1.2 What is a Jupyter Notebook \u00b6 Instead of writing code in a text file and then running the code with a Python command in the terminal, you can do all of your data analysis in one place. Code, output, tables, and charts can all be edited and viewed in one window in any web browser with Jupyter Notebooks . As the name suggests, this is a notebook to keep all of your ideas and data explorations in one place. In this tutorial, you use IBM Watson Studio to run a notebook. For this, you need a free IBM Cloud account. The following steps show you how sign up and get started. When you have the notebook up and running, you can go through the notebook. Jupyter notebooks are an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Info In this workshop we will use IBM Watson Studio to run a notebook. If you have not already done so, make sure that you do set up your account by following the workshop setup module. 1.3 What is Pandas \u00b6 Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. Throughout this workshop, we will be using Pandas to load, explore, and manipulate the data into the format needed for training our Machine Learning models later. 1.4 What is Seaborn \u00b6 While loading the data and exploring the statistical information about is useful, often times we find useful insight in visual representations of the data. This is why there are numerous open-source libraries available in Python to enable data visualization. matplotlib and seaborn are two of the most popular libraries in this category. Info seaborn vs. matplotlib : seaborn is a higher level library wrapped around matplotlib and it is highly tailored to visualizing the data structures that Pandas uses. This means that if you can achieve what you need using seaborn , that route will almost always be simpler and quicker. If you need more details on how to customize your plots or looking for the syntax to create specific plots, the best place to start is the documentation of matplotlib and the documentation of seaborn as they are filled with examples and sample codes. 2. Exercises \u00b6 2.1 Refresher \u00b6 For this workshop, you are only required to complete the refresher. However, if would like to start with simpler exercises to build your skills, check out the Optional Introductory Exercises section. Open the Jupyter notebook \u00b6 Go the (\u2630) navigation menu and under the Projects section click on View all projects . Click the project name you created in the workshop setup section. From your Project overview page, click on the Assets tab to open the assets page where your project assets are stored and organized. Scroll down to the Notebooks section of the page and click on the pencil icon at the right of the python-for-ml-refresher.ipynb notebook. Note You may see more notebooks than just the one in this screenshot. When the Jupyter notebook is loaded and the kernel is ready, we will be ready to start executing it in the next section. Run the Jupyter notebook \u00b6 Spend some time looking through the sections of the notebook to get an overview. A notebook is composed of text (markdown or heading) cells and code cells. The markdown cells provide comments on what the code is designed to do. You will run cells individually by highlighting each cell, then either click the Run button at the top of the notebook. While the cell is running, an asterisk ( [*] ) will show up to the left of the cell. When that cell has finished executing a sequential number will show up (i.e. [17] ). Hint You can also run a cell by pressing Shift + Enter on your keyboard instead of clicking the run ( ) button. Finish running all of the cells. Carefully read all of the markdown comments to gain some understanding of how data vizualization can be use to gain insight into the data set. 2.2 Optional Introductory Exercises \u00b6 There are additional notebooks in the file that you imported with names such as optional-<library name>-exercises where <library name> is the name of the library exercises included in that notebook. You can follow these notebooks first if you would like to start with more introductory exercises first to get up to speed with the tools used in this workshop To open these notebooks, follow the steps outlined in Open The Jupyter Notebook and in step 4, open one of the optional notebooks. Summary \u00b6 In this module we went through refresher exercises in Python, Pandas , and Seaborn which should prepare us for the rest of this workshop.","title":"Python for ML Refresher"},{"location":"01-python-and-pandas-refresher/#python-for-ml-refresher","text":"In this section we will do a quick review of the following topics which will help you refresh your python skills so you can follow the rest of this workshop. Note that while you could greatly benefit from the optional sections, you don't have to follow them for this workshop. Definitions What is Python What is a Jupyter Notebook What is Pandas What is Seaborn Exercises Refresher Open the Jupyter notebook Run the Jupyter notebook Optional Introductory Exercises","title":"Python for ML Refresher"},{"location":"01-python-and-pandas-refresher/#1-definitions","text":"","title":"1. Definitions"},{"location":"01-python-and-pandas-refresher/#11-what-is-python","text":"You might think that Python is only for developers and people with computer science degrees. However, Python is great for beginners, even those with little coding experience because it\u2019s free, open source, and runs on any platform. The Python packages documentation is great, and after an introductory course , you have a good foundation to build on. For Data Scientists, Python has become an invaluable tool. This notebook will help you get started or review the basics of Python.","title":"1.1 What is Python"},{"location":"01-python-and-pandas-refresher/#12-what-is-a-jupyter-notebook","text":"Instead of writing code in a text file and then running the code with a Python command in the terminal, you can do all of your data analysis in one place. Code, output, tables, and charts can all be edited and viewed in one window in any web browser with Jupyter Notebooks . As the name suggests, this is a notebook to keep all of your ideas and data explorations in one place. In this tutorial, you use IBM Watson Studio to run a notebook. For this, you need a free IBM Cloud account. The following steps show you how sign up and get started. When you have the notebook up and running, you can go through the notebook. Jupyter notebooks are an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and explanatory text. Info In this workshop we will use IBM Watson Studio to run a notebook. If you have not already done so, make sure that you do set up your account by following the workshop setup module.","title":"1.2 What is a Jupyter Notebook"},{"location":"01-python-and-pandas-refresher/#13-what-is-pandas","text":"Pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language. Throughout this workshop, we will be using Pandas to load, explore, and manipulate the data into the format needed for training our Machine Learning models later.","title":"1.3 What is Pandas"},{"location":"01-python-and-pandas-refresher/#14-what-is-seaborn","text":"While loading the data and exploring the statistical information about is useful, often times we find useful insight in visual representations of the data. This is why there are numerous open-source libraries available in Python to enable data visualization. matplotlib and seaborn are two of the most popular libraries in this category. Info seaborn vs. matplotlib : seaborn is a higher level library wrapped around matplotlib and it is highly tailored to visualizing the data structures that Pandas uses. This means that if you can achieve what you need using seaborn , that route will almost always be simpler and quicker. If you need more details on how to customize your plots or looking for the syntax to create specific plots, the best place to start is the documentation of matplotlib and the documentation of seaborn as they are filled with examples and sample codes.","title":"1.4 What is Seaborn"},{"location":"01-python-and-pandas-refresher/#2-exercises","text":"","title":"2. Exercises"},{"location":"01-python-and-pandas-refresher/#21-refresher","text":"For this workshop, you are only required to complete the refresher. However, if would like to start with simpler exercises to build your skills, check out the Optional Introductory Exercises section.","title":"2.1 Refresher"},{"location":"01-python-and-pandas-refresher/#open-the-jupyter-notebook","text":"Go the (\u2630) navigation menu and under the Projects section click on View all projects . Click the project name you created in the workshop setup section. From your Project overview page, click on the Assets tab to open the assets page where your project assets are stored and organized. Scroll down to the Notebooks section of the page and click on the pencil icon at the right of the python-for-ml-refresher.ipynb notebook. Note You may see more notebooks than just the one in this screenshot. When the Jupyter notebook is loaded and the kernel is ready, we will be ready to start executing it in the next section.","title":"Open the Jupyter notebook"},{"location":"01-python-and-pandas-refresher/#run-the-jupyter-notebook","text":"Spend some time looking through the sections of the notebook to get an overview. A notebook is composed of text (markdown or heading) cells and code cells. The markdown cells provide comments on what the code is designed to do. You will run cells individually by highlighting each cell, then either click the Run button at the top of the notebook. While the cell is running, an asterisk ( [*] ) will show up to the left of the cell. When that cell has finished executing a sequential number will show up (i.e. [17] ). Hint You can also run a cell by pressing Shift + Enter on your keyboard instead of clicking the run ( ) button. Finish running all of the cells. Carefully read all of the markdown comments to gain some understanding of how data vizualization can be use to gain insight into the data set.","title":"Run the Jupyter notebook"},{"location":"01-python-and-pandas-refresher/#22-optional-introductory-exercises","text":"There are additional notebooks in the file that you imported with names such as optional-<library name>-exercises where <library name> is the name of the library exercises included in that notebook. You can follow these notebooks first if you would like to start with more introductory exercises first to get up to speed with the tools used in this workshop To open these notebooks, follow the steps outlined in Open The Jupyter Notebook and in step 4, open one of the optional notebooks.","title":"2.2 Optional Introductory Exercises"},{"location":"01-python-and-pandas-refresher/#summary","text":"In this module we went through refresher exercises in Python, Pandas , and Seaborn which should prepare us for the rest of this workshop.","title":"Summary"},{"location":"02-regression/","text":"Regression Exercise \u00b6 What is regression in machine learning? \u00b6 Regression in machine learning is a technique used to predict a continuous value (also known as the target feature ) based on a set of input values ( features ). An example of this could be predicting prices of residential houses based on certain properties of the houses (eg. zip code, area, floors, garage type, etc). Objectives \u00b6 By the end of this module, the participant will have learned: What regression in Machine Learning is Basics of Data preparation for Regression Algorithms Basics of training a Regression Model using sklearn About the Dataset \u00b6 In this tutorial, we use a data set that contains various information that a home buyer considers before buying a house. We use this data to analyze how well we would be able to predict the house price given all of the other relevant information. Pay close attention to the pre-processing sections of the notebook associated with this module. The steps should give you an idea of the kinds of processing needed to prepare the data for regression models. Open the Jupyter notebook \u00b6 Go the (\u2630) navigation menu and under the Projects section click on All Projects . Click the project name you created in the Workshop Setup section. From your Project overview page, click on the Assets tab to open the assets page where your project assets are stored and organized. Scroll down to the Notebooks section of the page and click on the pencil icon at the right of the regression-exercises.ipynb notebook. Note You may see more notebooks than just the one in this screenshot. When the Jupyter notebook is loaded and the kernel is ready, we will be ready to start executing it in the next section. Run the Jupyter notebook \u00b6 Spend some time looking through the sections of the notebook to get an overview. A notebook is composed of text (markdown or heading) cells and code cells. The markdown cells provide comments on what the code is designed to do. You will run cells individually by highlighting each cell, then either click the Run button at the top of the notebook. While the cell is running, an asterisk ( [*] ) will show up to the left of the cell. When that cell has finished executing a sequential number will show up (i.e. [17] ). Hint You can also run a cell by pressing Shift + Enter on your keyboard instead of clicking the run ( ) button. Summary \u00b6 In this module we learned the basics of supervised machine learning using linear regression and built our first machine learning model. You should now have the basic building blocks that you need to Start using different algorithms to explore your data and use it to build models. Keep in mind that while this module is a great starting point, there is a lot more to be explored in the world of supervised machine learning and various types of algorithms to learn about. To learn more and for a more in-depth survey of commonly used algorithms in this field, click on the learn more button below and follow the learning path at your own time. If you are looking for a more in depth tutorial on different algorithms available for unsupervised learning, visit the following tutorial .","title":"Regression"},{"location":"02-regression/#regression-exercise","text":"","title":"Regression Exercise"},{"location":"02-regression/#what-is-regression-in-machine-learning","text":"Regression in machine learning is a technique used to predict a continuous value (also known as the target feature ) based on a set of input values ( features ). An example of this could be predicting prices of residential houses based on certain properties of the houses (eg. zip code, area, floors, garage type, etc).","title":"What is regression in machine learning?"},{"location":"02-regression/#objectives","text":"By the end of this module, the participant will have learned: What regression in Machine Learning is Basics of Data preparation for Regression Algorithms Basics of training a Regression Model using sklearn","title":"Objectives"},{"location":"02-regression/#about-the-dataset","text":"In this tutorial, we use a data set that contains various information that a home buyer considers before buying a house. We use this data to analyze how well we would be able to predict the house price given all of the other relevant information. Pay close attention to the pre-processing sections of the notebook associated with this module. The steps should give you an idea of the kinds of processing needed to prepare the data for regression models.","title":"About the Dataset"},{"location":"02-regression/#open-the-jupyter-notebook","text":"Go the (\u2630) navigation menu and under the Projects section click on All Projects . Click the project name you created in the Workshop Setup section. From your Project overview page, click on the Assets tab to open the assets page where your project assets are stored and organized. Scroll down to the Notebooks section of the page and click on the pencil icon at the right of the regression-exercises.ipynb notebook. Note You may see more notebooks than just the one in this screenshot. When the Jupyter notebook is loaded and the kernel is ready, we will be ready to start executing it in the next section.","title":"Open the Jupyter notebook"},{"location":"02-regression/#run-the-jupyter-notebook","text":"Spend some time looking through the sections of the notebook to get an overview. A notebook is composed of text (markdown or heading) cells and code cells. The markdown cells provide comments on what the code is designed to do. You will run cells individually by highlighting each cell, then either click the Run button at the top of the notebook. While the cell is running, an asterisk ( [*] ) will show up to the left of the cell. When that cell has finished executing a sequential number will show up (i.e. [17] ). Hint You can also run a cell by pressing Shift + Enter on your keyboard instead of clicking the run ( ) button.","title":"Run the Jupyter notebook"},{"location":"02-regression/#summary","text":"In this module we learned the basics of supervised machine learning using linear regression and built our first machine learning model. You should now have the basic building blocks that you need to Start using different algorithms to explore your data and use it to build models. Keep in mind that while this module is a great starting point, there is a lot more to be explored in the world of supervised machine learning and various types of algorithms to learn about. To learn more and for a more in-depth survey of commonly used algorithms in this field, click on the learn more button below and follow the learning path at your own time. If you are looking for a more in depth tutorial on different algorithms available for unsupervised learning, visit the following tutorial .","title":"Summary"},{"location":"03-classification/","text":"Classification Exercise \u00b6 What is classification in machine learning? \u00b6 Classification in machine learning is when the feature to be predicted contains categories of values. Each of these categories is considered as a class into which the predicted value falls and hence has its name, classification. An example of this could be predicting the parts of speech (verb, noun, adjective, etc.) of words within a given text. Objectives \u00b6 By the end of this module, the participant will have learned: What classification in Machine Learning is Basics of training a Naive Bayes Model using sklearn Basics of training a logistic regression model using sklearn About the DataSet \u00b6 In this tutorial, we use a data set that contains information about customers of an online trading platform to classify whether a given customer\u2019s probability of churn will be high, medium, or low. This provides a good example to learn how a classification model is built from start to end. The three classes that prediction will fall under are high, medium, and low. The data is available to us in the form of a .csv file and is imported using the pandas library. We use numpy and matplotlib to get some statistics and visualize data. Pay close attention to the pre-processing sections of the notebook associated with this module. The steps should give you an idea of the kinds of processing needed to prepare the data for classification models. Open the Jupyter notebook \u00b6 Go the (\u2630) navigation menu and under the Projects section click on All Projects . Click the project name you created in the Workshop Setup section. From your Project overview page, click on the Assets tab to open the assets page where your project assets are stored and organized. Scroll down to the Notebooks section of the page and click on the pencil icon at the right of the classification-exercise.ipynb notebook. Note You may see additional notebooks that differ from the ones in this screenshot. When the Jupyter notebook is loaded and the kernel is ready, we will be ready to start executing it in the next section. Run the Jupyter notebook \u00b6 Spend some time looking through the sections of the notebook to get an overview. A notebook is composed of text (markdown or heading) cells and code cells. The markdown cells provide comments on what the code is designed to do. You will run cells individually by highlighting each cell, then either click the Run button at the top of the notebook. While the cell is running, an asterisk ( [*] ) will show up to the left of the cell. When that cell has finished executing a sequential number will show up (i.e. [17] ). Hint You can also run a cell by pressing Shift + Enter on your keyboard instead of clicking the run ( ) button. Summary \u00b6 In this module we learned the basics of supervised machine learning using the Naive Bayes and logistic regression models and compared the effectiveness of the two against the actual data. To learn more and for a more in-depth survey of commonly used classification algorithms, click on the learn more button below and follow the learning path at your own time. Learn More about Classification","title":"Classification"},{"location":"03-classification/#classification-exercise","text":"","title":"Classification Exercise"},{"location":"03-classification/#what-is-classification-in-machine-learning","text":"Classification in machine learning is when the feature to be predicted contains categories of values. Each of these categories is considered as a class into which the predicted value falls and hence has its name, classification. An example of this could be predicting the parts of speech (verb, noun, adjective, etc.) of words within a given text.","title":"What is classification in machine learning?"},{"location":"03-classification/#objectives","text":"By the end of this module, the participant will have learned: What classification in Machine Learning is Basics of training a Naive Bayes Model using sklearn Basics of training a logistic regression model using sklearn","title":"Objectives"},{"location":"03-classification/#about-the-dataset","text":"In this tutorial, we use a data set that contains information about customers of an online trading platform to classify whether a given customer\u2019s probability of churn will be high, medium, or low. This provides a good example to learn how a classification model is built from start to end. The three classes that prediction will fall under are high, medium, and low. The data is available to us in the form of a .csv file and is imported using the pandas library. We use numpy and matplotlib to get some statistics and visualize data. Pay close attention to the pre-processing sections of the notebook associated with this module. The steps should give you an idea of the kinds of processing needed to prepare the data for classification models.","title":"About the DataSet"},{"location":"03-classification/#open-the-jupyter-notebook","text":"Go the (\u2630) navigation menu and under the Projects section click on All Projects . Click the project name you created in the Workshop Setup section. From your Project overview page, click on the Assets tab to open the assets page where your project assets are stored and organized. Scroll down to the Notebooks section of the page and click on the pencil icon at the right of the classification-exercise.ipynb notebook. Note You may see additional notebooks that differ from the ones in this screenshot. When the Jupyter notebook is loaded and the kernel is ready, we will be ready to start executing it in the next section.","title":"Open the Jupyter notebook"},{"location":"03-classification/#run-the-jupyter-notebook","text":"Spend some time looking through the sections of the notebook to get an overview. A notebook is composed of text (markdown or heading) cells and code cells. The markdown cells provide comments on what the code is designed to do. You will run cells individually by highlighting each cell, then either click the Run button at the top of the notebook. While the cell is running, an asterisk ( [*] ) will show up to the left of the cell. When that cell has finished executing a sequential number will show up (i.e. [17] ). Hint You can also run a cell by pressing Shift + Enter on your keyboard instead of clicking the run ( ) button.","title":"Run the Jupyter notebook"},{"location":"03-classification/#summary","text":"In this module we learned the basics of supervised machine learning using the Naive Bayes and logistic regression models and compared the effectiveness of the two against the actual data. To learn more and for a more in-depth survey of commonly used classification algorithms, click on the learn more button below and follow the learning path at your own time. Learn More about Classification","title":"Summary"},{"location":"04-AutoAI/","text":"Machine Learning Models with Auto AI \u00b6 In this workshop you will learn how to build and deploy your own AI Models. For the workshop we will be using AutoAI, a graphical tool that analyses your dataset and discovers data transformations, algorithms, and parameter settings that work best for your problem setting. Using AutoAI, you can build and deploy a machine learning model with sophisticated training features and no coding. We will use a public dataset to build and deploy model pipelines, and analyse the outcome. Set up \u00b6 Make sure that you have followed the steps in the project setup to create a project and set up your IBM Cloud account and Cloud Pak for Data as a Service. Add AutoAI experiment \u00b6 Go to your Project Overview page. Click on Add to Project on the top right and select AutoAI experiment . Associate a Machine Learning service \u00b6 Give your Auto AI experiment a unique name. Associate a Watson Machine Learning service instance . If you have already created one this will apear in the dropdown or you can create a new one by clicking on the link. Once this is done, click the Reload button for your Machine Learning service instance to appear. Once your Machine Learning service instance appears under \"Associated services\", click Create . Upload your Data Sets \u00b6 You have already added insurance.csv to your project assets when you created the analytics project in the project setup steps. Click Select from project and choose the insurance.csv file. Click Select asset . Once your dataset is successfully uploaded, you will be asked if you want to create a time series forecast. Click No . You will now be asked to select what you want to predict. Choose your prediction column as expenses . Optionally, go to the Experiment settings to make changes to the AutoAI Experiment. When you are ready to run the experiment, click on Run Experiment . Completed AutoAI experiment \u00b6 The experiment will take approximately 20 minutes to run. You can check on the progress during that time. When completed, it will show the results of the experiment. View the experiment results \u00b6 Once the experiment completes, you can explore the various pipelines and options in the UI. Some of the options available are to perform a Pipeline comparison , to see a log of the experiment, or to see the ranked listing of the pipelines (ranking based on the optimization metric in your experiment, in this case RMSE - the root mean squared error). The next step is to select the model that gives the best result and view its performance. In this case, Pipeline 7 gave the best result for our experiment. You can view the detailed results by clicking the corresponding pipeline name from the leaderboard. Save the pipeline as a model \u00b6 The model evaluation page will show metrics for the experiment, feature transformations that were performed (if any), which features contribute to the model, and more details of the pipeline. Optionally, feel free to click through these views of the pipeline details. Then click on tthe Save as button to save the model. On the next screen, select the asset type as Model . Keep the default name or change it, add an optional description and tags, and click Create to save it. You will receive a notification to indicate that your model is saved to your project. Clicking View in project within the notification will bring you to the model that is saved in your project. If you go back to your project main page by going to the left-hand navigator and clicking on your project's name, you can see the model listed under Models . (Optional) Save the pipeline as a notebook \u00b6 You can save pipelines generated in AutoAI experiments as notebooks if you want to view the code that created the model pipeline or interact with the model programmatically. Go back to your AutoAI experiment by clicking on the name of the experiment under the AutoAI experiments section on your project main page. Click on the name of the pipeline that you want to save. To save the pipeline as a notebook, click Save as . On the next screen, select the asset type as Notebook . Keep the default name or change it, add an optional description and tags, and click Create to save it. You will receive a notification to indicate that your notebook is saved to your project. Clicking View in project within the notification will bring you to the notebook that is saved in your project. If you go back to your project main page by going to the left-hand navigator and clicking on your project's name, you can see the notebook listed under Notebooks . Deploy the model \u00b6 Open your model by clicking on the name of the model listed in your project. Click on Promote to deployment space to deploy the model. Click on the dropdown to Select or create a space . If you have already created a deployment space, select it. Otherwise click on Create a new deployment space to create a new space. If you are creating a new space, provide a name for the space and choose your Machine Learning Service instance. Click Create to create the space. When you get a notification that the space is created, click Close to go back. Back on the \"Promote to space\" page, select the checkbox to Go to the model in the space after promoting it and click Promote . Once the model is promoted to the deployment space, you will be brought to the model within the deployment space. Click on New deployment . Select the deployment type as Online , provide a name and a serving name for the deployment and click Create . The deployment takes a few minutes. Once the status of the deployment changes to \"Deployed\", click on the deployment name. Test the model \u00b6 When the deployment is opened, you will be brought to the API reference tab . This tab contains code snippets (in various programming languages) that can be used to run the model. For now, click on the Test tab. Here you can test the model by providing the input using a form. Provide the following values in the form, then click Add to list . Click Predict . The expenses value predicted by the model will be shown in the Result section. age: 20 sex: male bmi: 33.8 children: 3 smoker: yes region: northwest Alternatively, you can test the model by providing the input using a JSON. Click on the Provide input data as JSON button, then replace the JSON in the \"Body\" section with the following JSON. Click Predict . The expenses value predicted by the model will be shown in the Result section. { \"input_data\" : [ { \"fields\" : [ \"age\" , \"sex\" , \"bmi\" , \"children\" , \"smoker\" , \"region\" ], \"values\" : [ [ 20 , \"male\" , 33.8 , 3 , \"yes\" , \"northwest\" ] ] } ] }","title":"AutoAI"},{"location":"04-AutoAI/#machine-learning-models-with-auto-ai","text":"In this workshop you will learn how to build and deploy your own AI Models. For the workshop we will be using AutoAI, a graphical tool that analyses your dataset and discovers data transformations, algorithms, and parameter settings that work best for your problem setting. Using AutoAI, you can build and deploy a machine learning model with sophisticated training features and no coding. We will use a public dataset to build and deploy model pipelines, and analyse the outcome.","title":"Machine Learning Models with Auto AI"},{"location":"04-AutoAI/#set-up","text":"Make sure that you have followed the steps in the project setup to create a project and set up your IBM Cloud account and Cloud Pak for Data as a Service.","title":"Set up"},{"location":"04-AutoAI/#add-autoai-experiment","text":"Go to your Project Overview page. Click on Add to Project on the top right and select AutoAI experiment .","title":"Add AutoAI experiment"},{"location":"04-AutoAI/#associate-a-machine-learning-service","text":"Give your Auto AI experiment a unique name. Associate a Watson Machine Learning service instance . If you have already created one this will apear in the dropdown or you can create a new one by clicking on the link. Once this is done, click the Reload button for your Machine Learning service instance to appear. Once your Machine Learning service instance appears under \"Associated services\", click Create .","title":"Associate a Machine Learning service"},{"location":"04-AutoAI/#upload-your-data-sets","text":"You have already added insurance.csv to your project assets when you created the analytics project in the project setup steps. Click Select from project and choose the insurance.csv file. Click Select asset . Once your dataset is successfully uploaded, you will be asked if you want to create a time series forecast. Click No . You will now be asked to select what you want to predict. Choose your prediction column as expenses . Optionally, go to the Experiment settings to make changes to the AutoAI Experiment. When you are ready to run the experiment, click on Run Experiment .","title":"Upload your Data Sets"},{"location":"04-AutoAI/#completed-autoai-experiment","text":"The experiment will take approximately 20 minutes to run. You can check on the progress during that time. When completed, it will show the results of the experiment.","title":"Completed AutoAI experiment"},{"location":"04-AutoAI/#view-the-experiment-results","text":"Once the experiment completes, you can explore the various pipelines and options in the UI. Some of the options available are to perform a Pipeline comparison , to see a log of the experiment, or to see the ranked listing of the pipelines (ranking based on the optimization metric in your experiment, in this case RMSE - the root mean squared error). The next step is to select the model that gives the best result and view its performance. In this case, Pipeline 7 gave the best result for our experiment. You can view the detailed results by clicking the corresponding pipeline name from the leaderboard.","title":"View the experiment results"},{"location":"04-AutoAI/#save-the-pipeline-as-a-model","text":"The model evaluation page will show metrics for the experiment, feature transformations that were performed (if any), which features contribute to the model, and more details of the pipeline. Optionally, feel free to click through these views of the pipeline details. Then click on tthe Save as button to save the model. On the next screen, select the asset type as Model . Keep the default name or change it, add an optional description and tags, and click Create to save it. You will receive a notification to indicate that your model is saved to your project. Clicking View in project within the notification will bring you to the model that is saved in your project. If you go back to your project main page by going to the left-hand navigator and clicking on your project's name, you can see the model listed under Models .","title":"Save the pipeline as a model"},{"location":"04-AutoAI/#optional-save-the-pipeline-as-a-notebook","text":"You can save pipelines generated in AutoAI experiments as notebooks if you want to view the code that created the model pipeline or interact with the model programmatically. Go back to your AutoAI experiment by clicking on the name of the experiment under the AutoAI experiments section on your project main page. Click on the name of the pipeline that you want to save. To save the pipeline as a notebook, click Save as . On the next screen, select the asset type as Notebook . Keep the default name or change it, add an optional description and tags, and click Create to save it. You will receive a notification to indicate that your notebook is saved to your project. Clicking View in project within the notification will bring you to the notebook that is saved in your project. If you go back to your project main page by going to the left-hand navigator and clicking on your project's name, you can see the notebook listed under Notebooks .","title":"(Optional) Save the pipeline as a notebook"},{"location":"04-AutoAI/#deploy-the-model","text":"Open your model by clicking on the name of the model listed in your project. Click on Promote to deployment space to deploy the model. Click on the dropdown to Select or create a space . If you have already created a deployment space, select it. Otherwise click on Create a new deployment space to create a new space. If you are creating a new space, provide a name for the space and choose your Machine Learning Service instance. Click Create to create the space. When you get a notification that the space is created, click Close to go back. Back on the \"Promote to space\" page, select the checkbox to Go to the model in the space after promoting it and click Promote . Once the model is promoted to the deployment space, you will be brought to the model within the deployment space. Click on New deployment . Select the deployment type as Online , provide a name and a serving name for the deployment and click Create . The deployment takes a few minutes. Once the status of the deployment changes to \"Deployed\", click on the deployment name.","title":"Deploy the model"},{"location":"04-AutoAI/#test-the-model","text":"When the deployment is opened, you will be brought to the API reference tab . This tab contains code snippets (in various programming languages) that can be used to run the model. For now, click on the Test tab. Here you can test the model by providing the input using a form. Provide the following values in the form, then click Add to list . Click Predict . The expenses value predicted by the model will be shown in the Result section. age: 20 sex: male bmi: 33.8 children: 3 smoker: yes region: northwest Alternatively, you can test the model by providing the input using a JSON. Click on the Provide input data as JSON button, then replace the JSON in the \"Body\" section with the following JSON. Click Predict . The expenses value predicted by the model will be shown in the Result section. { \"input_data\" : [ { \"fields\" : [ \"age\" , \"sex\" , \"bmi\" , \"children\" , \"smoker\" , \"region\" ], \"values\" : [ [ 20 , \"male\" , 33.8 , 3 , \"yes\" , \"northwest\" ] ] } ] }","title":"Test the model"},{"location":"05-wrap-up/","text":"Wrap up \u00b6 Thank you for participating in the Introduction to Machine Learning with sklearn workshop. We hope you have come away with some useful ideas and find that you can benefit from the content shared in this workshop. Summary of the workshop \u00b6 We started with an overview of Machine Learning, to learn what it is and how it works. We followed that up with a quick refresher lab on Python for Machine Learning. We performed two additional labs where we trained and tested Machine Learning models using regression and classification algorithms. Finally, we used AutoAI to automatically train and compare machine learning algorithms for the input data. Additional Resources \u00b6 You can learn more about Machine Learning using these resources: IBM Developer (Data Science) IBM Developer (Artificial Intelligence) AI Research at IBM Cloud Pak for Data Resources Cloud Pak for Data Hub Watson Studio Overview Watson Studio Learning Center Videos Watson Machine Learning Docs Keras Jupyter Notebooks Survey \u00b6 Please use this survey link to provide feedback for this workshop. It will help us improve upon the workshop itself and create relevant workshops for you in the future. Don't worry, the feedback is anonymous!","title":"Wrap-up"},{"location":"05-wrap-up/#wrap-up","text":"Thank you for participating in the Introduction to Machine Learning with sklearn workshop. We hope you have come away with some useful ideas and find that you can benefit from the content shared in this workshop.","title":"Wrap up"},{"location":"05-wrap-up/#summary-of-the-workshop","text":"We started with an overview of Machine Learning, to learn what it is and how it works. We followed that up with a quick refresher lab on Python for Machine Learning. We performed two additional labs where we trained and tested Machine Learning models using regression and classification algorithms. Finally, we used AutoAI to automatically train and compare machine learning algorithms for the input data.","title":"Summary of the workshop"},{"location":"05-wrap-up/#additional-resources","text":"You can learn more about Machine Learning using these resources: IBM Developer (Data Science) IBM Developer (Artificial Intelligence) AI Research at IBM Cloud Pak for Data Resources Cloud Pak for Data Hub Watson Studio Overview Watson Studio Learning Center Videos Watson Machine Learning Docs Keras Jupyter Notebooks","title":"Additional Resources"},{"location":"05-wrap-up/#survey","text":"Please use this survey link to provide feedback for this workshop. It will help us improve upon the workshop itself and create relevant workshops for you in the future. Don't worry, the feedback is anonymous!","title":"Survey"}]}